hist(myscores$SUCCESS)
names(myscores)
mydists <- list(ATTACK = "gaussian", DEFENSE = "gaussian", SUCCESS = "gaussian")
mydag <- matrix(data = c(1, 0, 0,
0, 1, 0,
0, 0, 0), byrow = TRUE, ncol = 3)
colnames(mydag) <- rownames(mydag) <- names(myscores)
mydag
mydag <- matrix(data = c(0, 0, 1,
0, 0, 1,
0, 0, 0), byrow = TRUE, ncol = 3)
colnames(mydag) <- rownames(mydag) <- names(myscores)
mydag
myres.c <- fitabn(dag.m=mydag, data.df=myscores, data.dists=mydists)
print(myres.c$mlik) ## log marginal likelihood goodness of fit
myres.c
library(highcharter)
install.packages(c("mlr", "nlme"))
install.packages("parallelMCMCcombine")
library("parallelMCMCcombine")
install.packages("sqldf")
library(DBI)
install.packages("RSQLite")
install.packages("filehash")
install.packages("bigmemory")
library(ff)
install.packages("ff")
install.packages("speedglm")
install.packages("biglm")
install.packages("biganalytics")
install.packages("ffbase")
install.packages("bigtabulate")
install.packages("biglars")
install.packages("bigrf")
install.packages("bigpca")
install.packages("bigalgebra")
install.packages("bigrf")
install.packages("inline")
install.packages("Rhipe")
install.packages("bigvis")
install.packages(c("RcppArmadillo", "mgcv"))
install.packages("SparkR")
devtools::install_github("rstudio/sparklyr")
library(sparklyr)
sc <- spark_connect(master = "local")
spark_install()
sc <- spark_connect(master = "local")
library(nycflights13)
library(Lahman)
install.packages("Lahman")
library(dplyr)
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
src_tbls(sc)
flights_tbl %>% filter(dep_delay == 2)
delay <- flights_tbl %>%
group_by(tailnum) %>%
summarise(count = n(), dist = mean(distance), delay = mean(arr_delay)) %>%
filter(count > 20, dist < 2000, !is.na(delay)) %>%
collect
# plot delays
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area(max_size = 2)
install.packages("rsparkling")
options(rsparkling.sparklingwater.version = "0.1.0")
library(rsparkling)
library(h2o)
library(dplyr)
# Open the Spark connection
sc <- spark_connect("local", version = "1.6.2")
# Load mtcars to Spark memory
mtcars_tbl <- copy_to(sc, mtcars, "mtcars")
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training, strict_version_check = FALSE)
test <- as_h2o_frame(sc, partitions$test, strict_version_check = FALSE)
training <- as_h2o_frame(sc, partitions$training, strict_version_check = TRUE)
training <- as_h2o_frame(sc, partitions$training, strict_version_check = FALSE)
partitions
?as_h2o_frame
training <- as_h2o_frame(sc, partitions$training, strict_version_check = FALSE)
library(rsparkling)
options(rsparkling.sparklingwater.version = "2.0.3")
options(rsparkling.sparklingwater.version = "1.6.8")
# Load libraries
library(rsparkling)
library(h2o)
library(dplyr)
sc <- spark_connect("local", version = "1.6.2")
library(sparklyr)
sc <- spark_connect("local", version = "1.6.2")
sc <- spark_connect("local")
options(warn = -1); options(scipen = 999)
suppressMessages(library(sparklyr))
sc <- spark_connect(master = "local")
suppressMessages(library(rsparkling))
options(rsparkling.sparklingwater.version = "1.6.8")
suppressMessages(library(h2o))
suppressMessages(library(dplyr))
mtcars_tbl <- copy_to(sc, mtcars, "mtcars")
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training, strict_version_check = FALSE)
test <- as_h2o_frame(sc, partitions$test, strict_version_check = FALSE)
spark_disconnect(sc)
options(warn = -1); options(scipen = 999)
# load packages
suppressMessages(if(!require(dplyr)){install.packages('dplyr'); library(dplyr)} else {library(dplyr)})
suppressMessages(if(!require(ggplot2)){install.packages('ggplot2'); library(ggplot2)} else {library(ggplot2)})
suppressMessages(if(!require(h2o)){install.packages('h2o'); library(h2o)} else {library(h2o)})
localH2O <- h2o.init(ip='127.0.0.1', port=54321)
filePath <- '/Users/haachicanoy/Documents/Online_courses/StatMachLearning/FLbigdataStats-master/bank_customer_data.csv'
market_data <- h2o.uploadFile(filePath,
destination_frame = '',
parse = TRUE,
header = TRUE,
sep = ',',
na.strings = c('unknown'),
progressBar = FALSE,
parse_type = 'CSV')
market_dataex1 <- market_data[,-11]
split_data <- h2o.splitFrame(market_dataex1, ratios=0.75)
train_data <- split_data[[1]]
validation_data <- split_data[[2]]
glm_model = h2o.glm(x = 1:19,
y = 20,
training_frame = train_data,
validation_frame = validation_data,
max_iterations = 100,
solver="L_BFGS",
family="binomial",
alpha = 1, #L2 regularisation
intercept = T)
summary(glm_model)
h2o.varimp(glm_model)
market_dataex2 <- market_data[,-21]
market_dataex2 <- market_dataex2[,c("housing", "job", "day", "qualification", "month", "location", "online.banking", "checking.account", "prev.sales", "year.contact", "central.interest.rate", "employment.rate", "customer.satisfaction", "price.index", "credit.rating", "age", "staff_total", "confidence.index", "emails.month", "length")]
split_data2 <- h2o.splitFrame(market_dataex2, ratios=0.75)
train_data2 <- split_data2[[1]]
validation_data2 <- split_data2[[2]]
glm_model2 = h2o.glm(x = 1:19,
y = 20,
training_frame = train_data2,
validation_frame = validation_data2,
max_iterations = 100,
solver="L_BFGS",
family="gaussian",
alpha = 1, #L2 regularisation
intercept = T)
summary(glm_model2)
h2o.varimp(glm_model2)
attach(market_data)
plot(market_data$day, market_data$length)
dim(train_data2)
dim(validation_data2)
h2o.shutdown(prompt = TRUE)
install.packages(c("RcppArmadillo", "bnlearn", "broom", "lmtest", "mgcv", "networkD3", "rpart.plot"))
install.packages(c("FactoMineR", "chron", "earth", "ggthemes", "stringr", "tseries"))
737717 * .3
737717 * .04
737717 * 7.5
install.packages('MicrosoftML')
install.packages(c("forecast", "h2o", "jsonlite", "rsparkling", "spdep", "statmod", "tm"))
library(highcharter)
library(dplyr)
library(viridisLite)
library(forecast)
library(treemap)
library(flexdashboard)
thm <-
hc_theme(
colors = c("#1a6ecc", "#434348", "#90ed7d"),
chart = list(
backgroundColor = "transparent",
style = list(fontFamily = "Source Sans Pro")
),
xAxis = list(
gridLineWidth = 1
)
)
data("usgeojson")
plot(usgeojson)
suppressMessages(if(!require(raster)){install.packages('raster'); library(raster)} else {library(raster)})
suppressMessages(if(!require(rgdal)){install.packages('rgdal'); library(rgdal)} else {library(rgdal)})
suppressMessages(if(!require(maptools)){install.packages('maptools'); library(maptools)} else {library(maptools)})
suppressMessages(if(!require(dplyr)){install.packages('dplyr'); library(dplyr)} else {library(dplyr)})
suppressMessages(if(!require(tidyr)){install.packages('tidyr'); library(tidyr)} else {library(tidyr)})
suppressMessages(if(!require(ggplot2)){install.packages('ggplot2'); library(ggplot2)} else {library(ggplot2)})
suppressMessages(if(!require(jsonlite)){install.packages('jsonlite'); library(jsonlite)} else {library(jsonlite)})
suppressMessages(if(!require(foreach)){install.packages('foreach'); library(foreach)} else {library(foreach)})
suppressMessages(if(!require(doMC)){install.packages('doMC'); library(doMC)} else {library(doMC)})
suppressMessages(if(!require(XML)){install.packages('XML'); library(XML)} else {library(XML)})
suppressMessages(if(!require(plspm)){install.packages('plspm'); library(plspm)} else {library(plspm)})
suppressMessages(library(compiler))
library(jsonlite)
library(rgdal)
install.packages("leaflet")
library(leaflet)
suppressMessages(if(!require(plspm)){install.packages('plspm'); library(plspm)} else {library(plspm)})
library(highcharter)
data("worldgeojson")
plot(worldgeojson)
worldgeojson
worldgeojson$`hc-transform`
worldgeojson$features
worldgeojson$crs
worldgeojson$title
worldgeojson$version
worldgeojson$type
worldgeojson$`hc-transform`
install.packages(c("commonmark", "mvtnorm", "tm"))
install.packages("mvtnorm")
install.packages(c("BBmisc", "DBI", "SparseM", "ctsem", "ggsci"))
install.packages("installr")
options(warn = -1); options(scipen = 999)
suppressMessages(if(!require(raster)){install.packages('raster'); library(raster)} else {library(raster)})
suppressMessages(if(!require(rgdal)){install.packages('rgdal'); library(rgdal)} else {library(rgdal)})
suppressMessages(if(!require(maptools)){install.packages('maptools'); library(maptools)} else {library(maptools)})
suppressMessages(if(!require(dplyr)){install.packages('dplyr'); library(dplyr)} else {library(dplyr)})
suppressMessages(if(!require(tidyr)){install.packages('tidyr'); library(tidyr)} else {library(tidyr)})
suppressMessages(if(!require(ggplot2)){install.packages('ggplot2'); library(ggplot2)} else {library(ggplot2)})
suppressMessages(if(!require(jsonlite)){install.packages('jsonlite'); library(jsonlite)} else {library(jsonlite)})
suppressMessages(if(!require(foreach)){install.packages('foreach'); library(foreach)} else {library(foreach)})
suppressMessages(if(!require(doMC)){install.packages('doMC'); library(doMC)} else {library(doMC)})
suppressMessages(if(!require(XML)){install.packages('XML'); library(XML)} else {library(XML)})
suppressMessages(if(!require(plspm)){install.packages('plspm'); library(plspm)} else {library(plspm)})
suppressMessages(if(!require(reshape)){install.packages('reshape'); library(reshape)} else {library(reshape)})
suppressMessages(library(compiler))
suppressMessages(if(!require(VIM)){install.packages('VIM'); library(VIM)} else {library(VIM)})
suppressMessages(if(!require(VIM)){install.packages('VIM'); library(VIM)} else {library(VIM)})
?kNN
install.packages("mice")
install.packages("Amelia")
install.packages("missForest")
library(Hmisc)
install.packages("Hmisc")
install.packages("mi")
install.packages('simputation', dependencies=TRUE)
install.packages(c("SparseM", "arules", "flexdashboard", "mclust", "revealjs"))
install.packages("proxy")
library("proxy", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
summary(pr_DB)
pr_DB$get_entry("Jaccard")
pr_DB$get_entry("Gower")
x <- matrix(sample(c(FALSE, TRUE), 8, rep = TRUE), ncol = 2)
dist(x, method = "Jaccard")
x <- matrix(rnorm(16), ncol = 4)
x
rownames(x) <- LETTERS[1:4]
colnames(x) <- letters[1:4]
dist(x)
dist(x, x)
install.packages("SimilarityMeasures")
library("SimilarityMeasures", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
path1 <- matrix(c(0, 1, 2, 3, 0, 1, 2, 3), 4)
path2 <- matrix(c(0, 1, 2, 3, 4, 5, 6, 7), 4)
path1
path2
DTW(path1, path2, 4)
install.packages(c("Rcpp", "RcppEigen", "cluster", "earth", "gRbase", "gbm", "ggpubr", "mclust", "mlr", "networkD3", "pbkrtest", "rsparkling", "rstan", "rstantools", "stringi", "survival"))
install.packages(c("OpenMx", "ade4", "earth", "psych", "readr"))
install.packages("tensorflow")
library(tensorflow)
# Create 100 phony x, y data points, y = x * 0.1 + 0.3
x_data <- runif(100, min=0, max=1)
y_data <- x_data * 0.1 + 0.3
# Try to find values for W and b that compute y_data = W * x_data + b
# (We know that W should be 0.1 and b 0.3, but TensorFlow will
# figure that out for us.)
W <- tf$Variable(tf$random_uniform(shape(1L), -1.0, 1.0))
install.packages(c("ade4", "bnlearn", "curl", "dendextend", "lattice", "loo", "maptools", "viridis"))
install.packages("dendextend")
install.packages(c("XML", "expm", "scatterplot3d", "shiny", "tibble"))
install.packages(c("DBI", "OpenMx", "RcppArmadillo", "VIM", "assertthat", "bayesplot", "ctsem", "curl", "filehash", "h2o", "jsonlite", "matrixStats", "ncdf4", "rgdal", "sourcetools", "spdep", "stringi", "survival", "zoo"))
install.packages(c("caret", "h2o", "quantreg", "readxl", "shiny", "tseries"))
install.packages(c("StanHeaders", "lme4", "markdown", "quantmod", "quantreg", "rpart.plot", "rstan", "tseries"))
install.packages(c("MASS", "boot", "earth", "memoise", "plspm", "rpart"))
library("plspm", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
detach("package:plspm", unload=TRUE)
install.packages(c("deldir", "earth", "plspm", "scatterplot3d"))
library("plspm", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
install.packages(c("SparseM", "deldir", "foreign"))
install.packages(c("Hmisc", "Matrix", "RcppEigen", "SparseM", "curl", "flexmix", "formatR", "glmnet", "h2o", "htmltools", "plotly", "rgdal", "rmarkdown", "shiny", "sparklyr", "spdep"))
install.packages(c("Hmisc", "XML", "glmnet", "psych"))
install.packages("timekit")
install.packages("tidyr")
install.packages("neuralnet")
library("neuralnet")
install.packages(c("OpenMx", "glmnet", "plotmo"))
options(warn = -1); options(scipen = 999)
# load packages
suppressMessages(if(!require(dplyr)){install.packages('dplyr'); library(dplyr)} else {library(dplyr)})
suppressMessages(if(!require(ggplot2)){install.packages('ggplot2'); library(ggplot2)} else {library(ggplot2)})
suppressMessages(if(!require(h2o)){install.packages('h2o'); library(h2o)} else {library(h2o)})
localH2O <- h2o.init(ip='127.0.0.1', port=54321)
filePath <- '/Users/haachicanoy/Documents/Online_courses/StatMachLearning/FLbigdataStats-master/bank_customer_data.csv'
market_data <- h2o.uploadFile(filePath,
destination_frame = '',
parse = TRUE,
header = TRUE,
sep = ',',
na.strings = c('unknown'),
progressBar = FALSE,
parse_type = 'CSV')
market_data
summary(market_data)
sample_frame <- h2o.splitFrame(market_data, ratio = 0.2)[[1]]
market_data_sample <- as.data.frame(sample_frame)
by_y_job <- market_data_sample %>% group_by(y, job) %>% tally()
by_y_job
ggplot(data = by_y_job, aes(x = job, y = n, fill = y)) + geom_bar(stat = "identity", position = "dodge")
market_dataex1 <- market_data[,-11]
split_data <- h2o.splitFrame(market_dataex1, ratios=0.75)
train_data <- split_data[[1]]
validation_data <- split_data[[2]]
glm_model = h2o.glm(x = 1:19,
y = 20,
training_frame = train_data,
validation_frame = validation_data,
max_iterations = 100,
solver="L_BFGS",
family="binomial",
alpha = 1, #L2 regularisation
intercept = T)
summary(glm_model)
h2o.varimp(glm_model)
market_dataex2 <- market_data[,-21]
market_dataex2 <- market_dataex2[,c("housing", "job", "day", "qualification", "month", "location", "online.banking", "checking.account", "prev.sales", "year.contact", "central.interest.rate", "employment.rate", "customer.satisfaction", "price.index", "credit.rating", "age", "staff_total", "confidence.index", "emails.month", "length")]
split_data2 <- h2o.splitFrame(market_dataex2, ratios=0.75)
train_data2 <- split_data2[[1]]
validation_data2 <- split_data2[[2]]
glm_model2 = h2o.glm(x = 1:19,
y = 20,
training_frame = train_data2,
validation_frame = validation_data2,
max_iterations = 100,
solver="L_BFGS",
family="gaussian",
alpha = 1, #L2 regularisation
intercept = T)
summary(glm_model2)
plot(market_data$day, market_data$length)
attach(market_data)
plot(market_data$day, market_data$length)
market_data
suppressMessages(if(!require(AER)){install.packages('AER'); library(AER)} else {library(AER)})
data("HousePrices")
View(HousePrices)
housing_data <- as.h2o(HousePrices)
response <- housing_data[,1]
response
covariates <- housing_data[,-1]
pca_model <- h2o.prcomp(training_frame = covariates,
k = 11,
max_iterations = 1000,
transform = "STANDARDIZE",
pca_method = "GramSVD"
)
summary(pca_model)
pca_model@model
pc_data <- h2o.predict(pca_model, covariates)
pc_data <- pc_data[,1:5]
pc_glm_data <- h2o.cbind(pc_data, response)
pc_glm_split <- h2o.splitFrame(pc_glm_data, ratios=0.75)
pc_train_data <- pc_glm_split[[1]]
pc_validation_data <- pc_glm_split[[2]]
glm_pca_model = h2o.glm(x = 1:5,
y=6,
training_frame = pc_train_data,
validation_frame = pc_validation_data,
max_iterations = 100,
solver = "L_BFGS",
family = "gaussian",
link = "identity",
alpha = 0,
lambda = 0,
intercept = T)
summary(glm_pca_model)
h2o.shutdown(prompt = TRUE)
install.packages(c("bit64", "devtools"))
devtools::install_github("alexioannides/pipeliner")
options(warn = -1); options(scipen = 999)
# load packages
suppressMessages(if(!require(dplyr)){install.packages('dplyr'); library(dplyr)} else {library(dplyr)})
suppressMessages(if(!require(ggplot2)){install.packages('ggplot2'); library(ggplot2)} else {library(ggplot2)})
suppressMessages(if(!require(h2o)){install.packages('h2o'); library(h2o)} else {library(h2o)})
localH2O <- h2o.init(ip='127.0.0.1', port=54321)
filePath <- '/Users/haachicanoy/Documents/Online_courses/StatMachLearning/FLbigdataStats-master/bank_customer_data.csv'
market_data <- h2o.uploadFile(filePath,
destination_frame = '',
parse = TRUE,
header = TRUE,
sep = ',',
na.strings = c('unknown'),
progressBar = FALSE,
parse_type = 'CSV')
cluster_data <- market_data[,-11]
cluster_data
market_data
cluster_data
ncol(market_data)
cluster_data <- market_data[,-c(11,ncol(market_data))]
cluster_data
cluster_model <- h2o.kmeans(training_frame = cluster_data,
k = 3,
standardize = T,
init = "Random"
)
summary(cluster_model)
varying_k <- function(k){
cluster_model <- h2o.kmeans(training_frame = cluster_data,
k = k,
standardize = T,
init = "Random"
)
# Examine the model
return(summary(cluster_model))
}
varying_k(k = 3)
varying_k(k = 2)
varying_k(k = 5)
varying_k(k = 10)
install.packages(c("R6", "plotrix", "rsconnect"))
install.packages("purrr")
library(highcharter)
10/12
8/12
5/6
suppressMessages(if(!require(rpart)){install.packages('rpart'); library(rpart)} else {library(rpart)})
suppressMessages(if(!require(rpart.plot)){install.packages('rpart.plot'); library(rpart.plot)} else {library(rpart.plot)})
data("ptitanic")
View(ptitanic)
first.tree <- rpart(survived ~ pclass + sex + age + sibsp + parch, data = ptitanic)
prp(first.tree)
View(ptitanic)
first.tree <- rpart(survived ~ pclass + sex + age + sibsp + parch, data = ptitanic)
prp(first.tree)
first.tree <- rpart(survived ~ pclass + sex + age + sibsp + parch, data = ptitanic)
prp(first.tree)
first.tree <- rpart(survived ~ pclass + sex + age + sibsp + parch, data = ptitanic)
prp(first.tree)
first.tree <- rpart(survived ~ pclass + sex + age + sibsp + parch, data = ptitanic)
prp(first.tree)
first.tree <- rpart(survived ~ pclass + sex + age + sibsp + parch, data = ptitanic)
prp(first.tree)
first.tree <- rpart(survived ~ pclass + sex + age + sibsp + parch, data = ptitanic)
prp(first.tree)
first.tree <- rpart(survived ~ pclass + sex + age + sibsp + parch, data = ptitanic)
prp(first.tree)
install.packages(c("devtools", "padr", "rticles", "tidyr"))
setwd("~/Repositories/r_scripts/image_classification")
X <- as.matrix(read.table(gzfile("zip.train.gz")))
View(X)
dim(X)
y2or3 <- which(X[, 1] == 2 | X[, 1] == 3)
X.train <- X[y2or3, -1]
y.train <- X[y2or3, 1] == 3
X.train
y.train
X <- as.matrix(read.table(gzfile("zip.test.gz")))
y2or3 <- which(X[, 1] == 2 | X[, 1] == 3)
X.test <- X[y2or3, -1]
y.test <- X[y2or3, 1] == 3
drawDigit <- function(x) {
for (i in 1:16) {
for (j in 1:16) {
color <- gray(1 - (1 + x[(i - 1) * 16 + j])/2)
grid.rect(j, 17 - i, 1, 1, default.units = "native",
gp = gpar(col = color, fill = color))
}
}
}
library(grid)
grid.newpage()
pushViewport(viewport(xscale = c(0, 6), yscale = c(0, 6)))
for (k in 1:25) {
pushViewport(viewport(x = (k - 1)%%5 + 1, y = 5 - floor((k - 1)/5), width = 1,
height = 1, xscale = c(0, 17), yscale = c(0, 17),
default.units = "native"))
drawDigit(X.train[k, ])
popViewport(1)
}
popViewport(1)
L <- lm(y.train ~ X.train)
yhat <- (cbind(1, X.test) %*% L$coef) >= 0.5
L.error <- mean(yhat != y.test)
library(class)
k <- c(1, 3, 5, 7, 15)
k.error <- rep(NA, length(k))
for (i in 1:length(k)) {
yhat <- knn(X.train, X.test, y.train, k[i])
k.error[i] <- mean(yhat != y.test)
}
error <- matrix(c(L.error, k.error), ncol = 1)
colnames(error) <- c("Error Rate")
rownames(error) <- c("Linear Regression", paste("k-NN with k =", k))
error
plot(c(1, 15), c(0, 1.1 * max(error)), type = "n", main = "Comparing Classifiers",
ylab = "Error Rate", xlab = "k")
abline(h = L.error, col = 2, lty = 3)
points(k, k.error, col = 4)
lines(k, k.error, col = 4, lty = 2)
g <- gc(reset = T)
rm(list = ls())
